{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33aee812-9149-41e7-a617-50abeac7ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "Working in folder C:\\Users\\miky_\\Documents\\Python\\PINNS_git/results/test_example_1_20231113-231258\n",
      "\n",
      "FCN(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (3): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "| Iter: 1 | Loss: 32.7539 | Total_time: 0.0min\n",
      "| Iter: 100 | Loss: 1.2260 | Total_time: 0.1min\n",
      "| Iter: 200 | Loss: 0.3169 | Total_time: 0.1min\n",
      "| Iter: 300 | Loss: 0.2222 | Total_time: 0.2min\n",
      "| Iter: 400 | Loss: 0.1654 | Total_time: 0.2min\n",
      "| Iter: 500 | Loss: 0.1134 | Total_time: 0.2min\n",
      "| Iter: 600 | Loss: 0.0939 | Total_time: 0.3min\n",
      "| Iter: 700 | Loss: 0.0738 | Total_time: 0.3min\n",
      "| Iter: 800 | Loss: 0.0495 | Total_time: 0.4min\n",
      "| Iter: 900 | Loss: 0.0389 | Total_time: 0.4min\n",
      "| Iter: 1000 | Loss: 0.1008 | Total_time: 0.4min\n",
      "| Iter: 1100 | Loss: 0.0243 | Total_time: 0.5min\n",
      "| Iter: 1200 | Loss: 0.0414 | Total_time: 0.5min\n",
      "| Iter: 1300 | Loss: 0.0269 | Total_time: 0.6min\n",
      "| Iter: 1400 | Loss: 0.0158 | Total_time: 0.6min\n",
      "| Iter: 1500 | Loss: 0.0147 | Total_time: 0.6min\n",
      "| Iter: 1600 | Loss: 0.0111 | Total_time: 0.7min\n",
      "| Iter: 1700 | Loss: 0.0099 | Total_time: 0.7min\n",
      "| Iter: 1800 | Loss: 0.0078 | Total_time: 0.8min\n",
      "| Iter: 1900 | Loss: 0.0135 | Total_time: 0.8min\n",
      "| Iter: 2000 | Loss: 0.0112 | Total_time: 0.8min\n",
      "| Iter: 2100 | Loss: 0.0142 | Total_time: 0.9min\n",
      "| Iter: 2200 | Loss: 0.0074 | Total_time: 0.9min\n",
      "| Iter: 2300 | Loss: 0.0646 | Total_time: 1.0min\n",
      "| Iter: 2400 | Loss: 0.0047 | Total_time: 1.0min\n",
      "| Iter: 2500 | Loss: 0.0038 | Total_time: 1.0min\n",
      "| Iter: 2600 | Loss: 0.0033 | Total_time: 1.1min\n",
      "| Iter: 2700 | Loss: 0.0030 | Total_time: 1.1min\n",
      "| Iter: 2800 | Loss: 0.0254 | Total_time: 1.2min\n",
      "| Iter: 2900 | Loss: 0.0175 | Total_time: 1.2min\n",
      "| Iter: 3000 | Loss: 0.0041 | Total_time: 1.2min\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Libraries\n",
    "#################\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils.plots import plot_mesh\n",
    "from utils.utils import create_tests_folder\n",
    "from utils.gen_plots import generate_gif\n",
    "from utils.gen_data import data_gen\n",
    "from utils.fcn_module import FCN\n",
    "from pyDOE import lhs  # Latin Hypercube Sampling\n",
    "\n",
    "\n",
    "#################\n",
    "#  Device configuration\n",
    "#################\n",
    "\n",
    "# Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Set the device, if CUDA is installed we use the GPU, otherwise we use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "if device == \"cuda\":\n",
    "    print(torch.cuda.get_device_name())\n",
    "\n",
    "#################\n",
    "# Tunning Parameters\n",
    "#################\n",
    "\n",
    "steps = 3000  # Number of steps in the optimization\n",
    "batch_size = 1000  # Batch size in the optimization\n",
    "w_bc = 100  # Extra weights for the loss_bc functional\n",
    "w_pde = 1  # Extra weights for the loss_pde functional\n",
    "lr = 1e-3  # Learning rate for the stochastic gradient descent\n",
    "layers = np.array([2, 50, 50, 50, 50, 1])  # Number of neurons on each layer of the fully connected neural network\n",
    "log_freq = 50  # log frequency\n",
    "\n",
    "## Choose the example. Each example has different domain and sourse term.\n",
    "case = \"example_1\"\n",
    "if case == \"example_1\":\n",
    "    domain = [-1, 1, 0, 1]\n",
    "elif case == \"example_2\":\n",
    "    domain = [0, 1, 0, 10]\n",
    "\n",
    "# Define the number of training/test data\n",
    "N_test_x = 200  #  Number of testing points in space @@@ actually\n",
    "N_test_t = 200  #  Number of testing points in time\n",
    "N_train_x = 150  #  Number of training points in space\n",
    "N_train_t = 150  #  Number of training points in time\n",
    "N_bc = 1000  #  Number of training points on the boundary\n",
    "\n",
    "# Create a folder with the results\n",
    "test_folder = create_tests_folder(parent_folder=\"results\", prefix=f\"_{case}\")\n",
    "if not os.path.exists(test_folder):\n",
    "    os.makedirs(test_folder)\n",
    "logging.basicConfig(handlers=[logging.StreamHandler(sys.stdout), logging.FileHandler(test_folder + \"/0_log.txt\")], level=logging.INFO, format=\"%(message)s\")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "#################\n",
    "# Generate data\n",
    "#################\n",
    "\n",
    "DG = data_gen(domain, case)\n",
    "x_train_pde = DG.get_PDE_dataset(N_train_x, N_train_t)\n",
    "x_train_bc, y_train_bc = DG.get_BC_dataset(N_bc)  # Generate the train dataset (time and space)\n",
    "y_real, x_test, y_test, X, T = DG.get_test_dataset(N_test_x, N_test_t)\n",
    "\n",
    "##########\n",
    "# Is it possible to use Latin Hypercube Sampling instead of the get_PDE_dataset function\n",
    "# lb = x_test[0]  # first value\n",
    "# ub = x_test[-1]  # last value\n",
    "# x_train_pde = lb + (ub - lb) * lhs(2, N_train_x*N_test_t)  # Choose 20000 points, 2 as the inputs are x and t\n",
    "##########\n",
    "\n",
    "\n",
    "# If the device is CUDA (CUDA is installed), the data are sent to the GPU\n",
    "x_train_bc = x_train_bc.float().to(device)  # Training Points (BC)\n",
    "y_train_bc = y_train_bc.float().to(device)  # Training Points (BC)\n",
    "x_train_pde = x_train_pde.float().to(device)  # Collocation Points\n",
    "X_test = x_test.float().to(device)  # the input dataset (complete)\n",
    "Y_test = y_test.float().to(device)  # the real solution\n",
    "\n",
    "#################\n",
    "# Create Model and Optimazer\n",
    "#################\n",
    "\n",
    "PINN = FCN(layers, case, domain)\n",
    "PINN.to(device)\n",
    "print(PINN)\n",
    "optimizer = torch.optim.Adam(PINN.parameters(), lr=lr, amsgrad=False)\n",
    "\n",
    "# It is possible to consider another optimazer\n",
    "# L-BFGS Optimizer\n",
    "# optimizer = torch.optim.LBFGS(PINN.parameters(), lr=lr,\n",
    "#                               max_iter = steps,\n",
    "#                               max_eval = None,\n",
    "#                               tolerance_grad = 1e-05,\n",
    "#                               tolerance_change = 1e-09,\n",
    "#                               history_size = 100,\n",
    "#                               line_search_fn = 'strong_wolfe')\n",
    "\n",
    "#################\n",
    "# Training process\n",
    "#################\n",
    "\n",
    "# Creating a root directory to store information\n",
    "res_dict = {\"loss\": [], \"loss_bc\": [], \"loss_pde\": [], \"rela_err_l2\": []}\n",
    "start_time_a = time.time()\n",
    "count = 1\n",
    "plot_mesh(X, T, y_real, case, name=f\"0_real\", error=0, folder=test_folder)  # plot real solution\n",
    "for i in range(1, steps + 1):\n",
    "    idx = np.random.choice(x_train_pde.shape[0], batch_size, replace=False)  # Choose randomly a batch in x_train_pde\n",
    "    loss = PINN.loss(x_train_bc, y_train_bc, x_train_pde[idx, :], w_bc=w_bc, w_pde=w_pde)  # use mean squared error\n",
    "    optimizer.zero_grad()  # We 'clean' the optimazer\n",
    "    loss.backward()  # Backpropagation (compute the gradients)\n",
    "    optimizer.step()  # Actualization of the parameters\n",
    "    # optimizer.step(PINN.closure) # L-BFGS Optimizer\n",
    "\n",
    "    # Create the plots with the solution with the current parameters, and the relative error.\n",
    "    res_dict[\"loss\"].append(loss.item())\n",
    "    with torch.no_grad():\n",
    "        err_l2_mean, error = PINN.error_l2_norm(X_test, Y_test)\n",
    "        res_dict[\"rela_err_l2\"].append(err_l2_mean.item())\n",
    "    if i % log_freq == 0 or i == 1:\n",
    "        u_predict = PINN(X_test)\n",
    "        arr_y1 = u_predict.reshape(shape=[N_test_t, N_test_x]).transpose(1, 0).detach().cpu()\n",
    "        plot_mesh(X, T, arr_y1, case, name=f\"approx_{count}\", loss=loss.item(), folder=test_folder, iter=i)\n",
    "        # error = error.reshape(shape=[N_test_t, N_test_x]).transpose(1, 0).detach()\n",
    "        # plot_mesh(X, T, error, name=f\"error_{count}\", error=err_l2_mean, folder=test_folder, iter=i)\n",
    "        if i % (log_freq*2) == 0 or i == 1:\n",
    "            logger.info(f\"| Iter: {i} | Loss: {loss.item():.4f} | Total_time: {(time.time() - start_time_a)/60:.1f}min\")\n",
    "        count += 1\n",
    "    # path = test_folder + \"/A_results_dict.npy\"\n",
    "    # np.save(path, np.asarray(res_dict, dtype=object))\n",
    "print('Finished training')\n",
    "#################\n",
    "# Animation\n",
    "#################\n",
    "\n",
    "# Generate animations showing the convergence to the real solution, and the relative error\n",
    "## It is necessary to have the imageio_ffmpeg  (pip install imageio_ffmpeg)\n",
    "generate_gif(test_folder, count, remove_imgs=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
